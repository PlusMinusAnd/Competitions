import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
from scipy.stats import pearsonr
from lightgbm import LGBMRegressor, early_stopping, log_evaluation
from xgboost import XGBRegressor
from catboost import CatBoostRegressor
import datetime
import os

# ì‹œë“œ ê³ ì •
r = 394
np.random.seed(r)

# ğŸ“Œ í‰ê°€ í•¨ìˆ˜ ì •ì˜
def print_scores(y_true, y_pred, label=""):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    nrmse = rmse / (np.max(y_true) - np.min(y_true))
    pearson = pearsonr(y_true, y_pred)[0]
    score = 0.5 * (1 - min(nrmse, 1)) + 0.5 * np.clip(pearson, 0, 1)
    print(f"ğŸ“Š {label} ê²°ê³¼")
    print(f"RMSE     : {rmse:.5f}")
    print(f"NRMSE    : {nrmse:.5f}")
    print(f"Pearson  : {pearson:.5f}")
    print(f"ScoreğŸ“ˆ  : {score:.5f}")
    return score

# ğŸ”¹ ë°ì´í„° ë¡œë“œ
train = pd.read_csv("./Drug/_02/full_pipeline/0_dataset/train_descriptor.csv")
test = pd.read_csv("./Drug/_02/full_pipeline/0_dataset/test_descriptor.csv")
X = train.drop(columns=["Inhibition"])
y = train["Inhibition"].values
X_test = test.copy()

# âœ… ìµœì  íŒŒë¼ë¯¸í„° (Optuna íŠœë‹ ê²°ê³¼ ì…ë ¥)
param_lgbm = {
    "n_estimators": 1000,
    "learning_rate": 0.024615467196152204,
    "max_depth": 3,
    "num_leaves": 31,
    "min_child_samples": 20,
    "colsample_bytree": 0.6411145386746391,
    "random_state": r,
    "verbosity": -1
}

param_xgb = {
    "n_estimators": 1000,
    'learning_rate': 0.04018614797174392,
    'max_depth': 3,
    'subsample': 0.7086680178296805,
    'colsample_bytree': 0.6201094943343927,
    'reg_alpha': 3.056666214937805,
    'reg_lambda': 2.370292354775882,
    "random_state": r,
    "verbosity": 0
}

param_cat = {
    "iterations": 1000,
    "learning_rate": 0.03905462846751998,
    "depth": 4,
    "l2_leaf_reg": 6.738080359145052,
    "bagging_temperature": 0.4929876007310619,
    "verbose": 0,
    "random_seed": r
}

# ğŸ”¹ ëª¨ë¸ ì •ì˜
models = {
    "lgbm": LGBMRegressor(**param_lgbm),
    "xgb": XGBRegressor(**param_xgb, early_stopping_rounds=20,),
    "cat": CatBoostRegressor(**param_cat)
}

kf = KFold(n_splits=5, shuffle=True, random_state=r)
oof_preds = {name: np.zeros(len(X)) for name in models}
test_preds = {name: np.zeros(len(X_test)) for name in models}

print("ğŸ”¹ Boosting ëª¨ë¸ë³„ 5-Fold í•™ìŠµ ì‹œì‘")

for name, model in models.items():
    print(f"âœ… {name.upper()} ì‹œì‘")
    for train_idx, val_idx in kf.split(X):
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]

        if name == "lgbm":
            model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                eval_metric="rmse",
                callbacks=[early_stopping(20), log_evaluation(period=0)]
            )
        elif name == "xgb":
            model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                
                verbose=False
            )
        elif name == "cat":
            model.fit(
                X_train, y_train,
                eval_set=(X_val, y_val),
                early_stopping_rounds=20,
                use_best_model=True
            )

        oof_preds[name][val_idx] = model.predict(X_val)
        test_preds[name] += model.predict(X_test) / kf.n_splits

    print_scores(y, oof_preds[name], label=name.upper())

# ğŸ”¹ ì•™ìƒë¸” ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰ (OOF ê¸°ì¤€)
best_score = -np.inf
best_weights = None
alphas = np.linspace(0, 1, 11)

for a in alphas:
    for b in alphas:
        if a + b > 1: continue
        c = 1 - a - b
        blended = a * oof_preds["lgbm"] + b * oof_preds["xgb"] + c * oof_preds["cat"]
        score = print_scores(y, blended, label=f"LGBM={a:.2f}, XGB={b:.2f}, CAT={c:.2f}")
        if score > best_score:
            best_score = score
            best_weights = (a, b, c)

a, b, c = best_weights
print(f"âœ… ìµœì  ê°€ì¤‘ì¹˜: LGBM={a:.2f}, XGB={b:.2f}, CAT={c:.2f} | Score: {best_score:.5f}")

final_oof = a * oof_preds["lgbm"] + b * oof_preds["xgb"] + c * oof_preds["cat"]
final_test = a * test_preds["lgbm"] + b * test_preds["xgb"] + c * test_preds["cat"]

print_scores(y, final_oof, label="Final Stacked Ensemble")

# ğŸ”¹ ì €ì¥
submission = pd.DataFrame({
    "ID": pd.read_csv("./Drug/test.csv")["ID"],
    "Inhibition": final_test
})

now = datetime.datetime.now().strftime("%Y%m%d_%H%M")
filename = f"submission_boost_best_{r}_{now}.csv"
save_path = f"./Drug/_02/full_pipeline/{filename}"
submission.to_csv(save_path, index=False)

np.save("./Drug/_02/full_pipeline/boost_oof_best.npy", final_oof)
np.save("./Drug/_02/full_pipeline/boost_preds_best.npy", final_test)

print(f"âœ… ìµœì¢… ì˜ˆì¸¡ ì €ì¥ ì™„ë£Œ â†’ {filename}")
