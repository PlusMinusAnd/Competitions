##### DNN ë°ì´í„° ì œì‘ ë° ì•™ìƒë¸”(with DMPNN, DNN) #####

import pandas as pd
import numpy as np
import joblib
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold

# ì‹œë“œ ê³ ì •
np.random.seed(73)

### 1. DNN ì˜ˆì¸¡ (RandomForest) ###
print("ğŸ”¹ DNN í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œì‘")

# RDKit descriptor ê¸°ë°˜ ë°ì´í„° ë¡œë“œ
train = pd.read_csv("./Drug/_02/0_dataset/train_descriptor.csv")
test = pd.read_csv("./Drug/_02/0_dataset/test_descriptor.csv")

X = train.drop(columns=["Inhibition"])
y = train["Inhibition"]
X_test = test.copy()

# ê²°ì¸¡ê°’ ì²˜ë¦¬
X = X.fillna(X.mean())
X_test = X_test.fillna(X.mean())

# ëª¨ë¸ ì •ì˜
model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=73)

# Cross-validation + ì˜ˆì¸¡
kf = KFold(n_splits=5, shuffle=True, random_state=73)
oof = np.zeros(len(X))
test_preds = np.zeros(len(X_test))

for train_idx, val_idx in kf.split(X):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
    
    model.fit(X_train, y_train)
    oof[val_idx] = model.predict(X_val)
    test_preds += model.predict(X_test) / kf.n_splits

# í‰ê°€
rmse = np.sqrt(mean_squared_error(y, oof))
print(f"âœ… DNN (RF) CV RMSE: {rmse:.4f}")

### 2. DMPNN ê²°ê³¼ ë¡œë“œ ###
print("ğŸ”¹ DMPNN ì˜ˆì¸¡ ë¡œë“œ")
dmpnn_preds = pd.read_csv("./Drug/_02/1_dmpnn/submission_dmpnn.csv")["Inhibition"].values

### 3. ì•™ìƒë¸” ###
print("ğŸ”¹ ì•™ìƒë¸” ìˆ˜í–‰ (0.5 DNN + 0.5 DMPNN)")
final_preds = 0.5 * test_preds + 0.5 * dmpnn_preds

# OOF ë° test ì˜ˆì¸¡ ì €ì¥
np.save("./Drug/_02/2_npy/dnn_oof.npy", oof)
np.save("./Drug/_02/2_npy/dnn_preds.npy", test_preds)
print("âœ… oof ì €ì¥ ì™„ë£Œ")

# ì €ì¥
submission = pd.DataFrame({
    "ID": pd.read_csv("./Drug/test.csv")["ID"],
    "Inhibition": final_preds
})
submission.to_csv("./Drug/_02/3_submission/submission_ensemble.csv", index=False)
print("âœ… submission_ensemble.csv ì €ì¥ ì™„ë£Œ")


